{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepScript.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "157DU1t2Z5Yt"
      },
      "cell_type": "markdown",
      "source": [
        "# **Uploading Files onto Google Colab**\n",
        "\n",
        "Word Embeddings have been uploaded on Google Drive in a folder called **Word2Vec**.\n",
        "\n",
        "They were trained by the Gensim module with dimensions of both 200 and 300, window size of 5, and 500 iterations.\n",
        "\n",
        "Here, we will access those files. \n",
        "\n",
        "Note: The URL for the Word2Vec folder in my Google Drive is : https://drive.google.com/drive/folders/1sdDeXX3XTdJg5tEnQNhmjNmol7DPzOZH\n",
        "\n",
        "That is why I set the the q paramter is set to: **1sdDeXX3XTdJg5tEnQNhmjNmol7DPzOZH**\n",
        "\n",
        "You will want to make a copy of the Word2Vec folder and put it in your Google Drive's 'Colab Notebooks' folder. Then you will want to change the q parameter to the end of the URL of the Word2Vec folder."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4ufZnIqP_GWV",
        "outputId": "49e56948-ab74-4dc9-9660-587cad6ce0fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "local_download_path = os.path.expanduser('~/Word2Vec')\n",
        "try:\n",
        "  os.makedirs(local_download_path)\n",
        "except: pass\n",
        "\n",
        "file_list = drive.ListFile(\n",
        "    {'q': \"'1sdDeXX3XTdJg5tEnQNhmjNmol7DPzOZH' in parents\"}).GetList()\n",
        "\n",
        "for f in file_list:\n",
        "  # 3. Create & download by id.\n",
        "  print('title: %s, id: %s' % (f['title'], f['id']))\n",
        "  fname = os.path.join(local_download_path, f['title'])\n",
        "  print('downloading to {}'.format(fname))\n",
        "  f_ = drive.CreateFile({'id': f['id']})\n",
        "  f_.GetContentFile(fname)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: Bad Sentences.csv, id: 1zcZm3griSFElsa2te1Hhd5lpAl7tl5vI\n",
            "downloading to /root/Word2Vec/Bad Sentences.csv\n",
            "title: Good Sentences.csv, id: 1dSk6Zq20YnP51fQqqjR65eERDaFRSrdb\n",
            "downloading to /root/Word2Vec/Good Sentences.csv\n",
            "title: Tokenized Bad Sentences.csv, id: 1n5XEE1aHdoAfBxrqXWn-yEeEjp2WUj1B\n",
            "downloading to /root/Word2Vec/Tokenized Bad Sentences.csv\n",
            "title: word2vec_Good_300, id: 1zWEoKRHFRToBzqkLLvA00N2HBcDvG_4F\n",
            "downloading to /root/Word2Vec/word2vec_Good_300\n",
            "title: word2vec_Good_200, id: 1NT7o_yI1IAHfGFcw9Wrq3CKNeC9md4T2\n",
            "downloading to /root/Word2Vec/word2vec_Good_200\n",
            "title: word2vec_Bad_300, id: 1zv6AxhipBjhD1rwID1HTE5zncVJPVGms\n",
            "downloading to /root/Word2Vec/word2vec_Bad_300\n",
            "title: word2vec_Bad_200, id: 1Giw1gcBYoncfYMGi6LKtEJIeYZ_a2PcC\n",
            "downloading to /root/Word2Vec/word2vec_Bad_200\n",
            "title: Tokenized Good Sentences.csv, id: 1YPAgpNciFdTAKQUsrcRs0RLaivevlNoT\n",
            "downloading to /root/Word2Vec/Tokenized Good Sentences.csv\n",
            "title: Tokenized Bad Sentences.csv, id: 1S8P8EC47oT46b7ql-xht2QT0rqMCy0yA\n",
            "downloading to /root/Word2Vec/Tokenized Bad Sentences.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "uJT1SxtinnjM"
      },
      "cell_type": "markdown",
      "source": [
        "# Importing Tokenized Sentences\n",
        "\n",
        "I have also uploaded two csv files called **Tokenized Bad Sentences.csv** and **Tokenized Good Sentences.csv**  found in the Word2Vec folder. \n",
        "\n",
        "Below is the code to read in those files."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xfdxBIsSkjuk",
        "outputId": "2507bc0e-5662-4a05-b8c0-789e8508566e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "import csv\n",
        "with open('/root/Word2Vec/Bad Sentences.csv', 'r', encoding=\"utf-8\") as f:\n",
        "    reader = csv.reader(f)\n",
        "    badSentences = list(reader)\n",
        "    \n",
        "with open('/root/Word2Vec/Good Sentences.csv', 'r', encoding=\"utf-8\") as f:\n",
        "    reader = csv.reader(f)\n",
        "    goodSentences = list(reader)\n",
        "    \n",
        "print(badSentences[0:10])   \n",
        "print(goodSentences[0:10])  "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['oh', ',', 'shit', '.'], ['you', 'just', 'got', 'wolfed', '.'], ['what', '?'], ['that', 'is', 'an', 'official', 'trademark', 'that', 'i', 'am', 'getting', 'registered', '.'], ['it', \"'s\", 'a', 'lot', 'of', 'stuff', 'you', 'got', 'ta', 'do', ',', 'hoops', 'you', 'got', 'ta', 'jump', 'through', '.'], ['got', 'ta', 'get', 'on', 'the', 'internet', '.'], ['got', 'ta', 'go', 'to', 'some', 'stupidass', 'website', 'where', 'you', 'register', 'a', 'catch', 'phrase', '.'], ['i', 'wanted', '``', 'bam', ',', \"''\", 'but', 'emeril', 'had', 'taken', 'it', '.'], ['i', \"'m\", 'rambling', ',', 'man', '.'], ['get', 'up', ',', 'man', '.']]\n",
            "[['mr.', 'dufresne', ',', 'describe', 'the', 'confrontation', 'you', 'had', 'with', 'your', 'wife', 'the', 'night', 'she', 'was', 'murdered', '.'], ['it', 'was', 'very', 'bitter', '.'], ['she', 'said', 'she', 'was', 'glad', 'i', 'knew', ',', 'that', 'she', 'hated', 'all', 'the', 'sneaking', 'around', '.'], ['and', 'she', 'said', 'that', 'she', 'wanted', 'a', 'divorce', 'in', 'reno', '.'], ['what', 'was', 'your', 'response', '?'], ['i', 'told', 'her', 'i', 'would', 'not', 'grant', 'one', '.'], ['``', 'i', \"'ll\", 'see', 'you', 'in', 'hell', 'before', 'i', 'see', 'you', 'in', 'reno', '.'], [\"''\", 'those', 'were', 'your', 'words', ',', 'according', 'to', 'your', 'neighbors', '.'], ['if', 'they', 'say', 'so', '.'], ['i', 'really', 'do', \"n't\", 'remember', '.']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "YmIy6TDWaJ0k"
      },
      "cell_type": "markdown",
      "source": [
        "# **Installing gensim**\n",
        "\n",
        "Gensim is the Python module used to train the word2vec embeddings. Here is how to upload the files."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cfn6Z8SxXu4W",
        "outputId": "eac18733-967f-4d7c-f2e2-e444e78bc7a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q gensim\n",
        "from gensim.models import Word2Vec\n",
        "model_Bad = Word2Vec.load(\"/root/Word2Vec/word2vec_Bad_300\")\n",
        "model_Good = Word2Vec.load(\"/root/Word2Vec/word2vec_Good_300\")\n",
        "print(model_Bad)\n",
        "print(model_Good)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=29504, size=300, alpha=0.025)\n",
            "Word2Vec(vocab=30426, size=300, alpha=0.025)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "qUR_r-pdaQRD"
      },
      "cell_type": "markdown",
      "source": [
        "# **Similar Vectors**\n",
        "\n",
        "Once the word2vec embeddings are uploaded, you can view the vectors most similar to a given word. "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "D33t0UbuZaHI",
        "outputId": "ee2dc10e-1c05-411f-8ed6-c056469218bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        }
      },
      "cell_type": "code",
      "source": [
        "for i in model_Bad.wv.most_similar (positive = 'good'):\n",
        "  print(i)\n",
        "  \n",
        "print()\n",
        "\n",
        "for i in model_Good.wv.most_similar (positive = 'good'):\n",
        "  print(i)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('bad', 0.42860960960388184)\n",
            "('nice', 0.40062108635902405)\n",
            "('like', 0.3491782248020172)\n",
            "('tough', 0.3429213762283325)\n",
            "('great', 0.34254634380340576)\n",
            "('better', 0.28865498304367065)\n",
            "('big', 0.28429123759269714)\n",
            "('weird', 0.2701437175273895)\n",
            "('happy', 0.26822713017463684)\n",
            "('hard', 0.26718002557754517)\n",
            "\n",
            "('bad', 0.5157124996185303)\n",
            "('nice', 0.42234158515930176)\n",
            "('great', 0.3885391056537628)\n",
            "('smart', 0.3636835813522339)\n",
            "('fine', 0.3554360568523407)\n",
            "('tough', 0.34922707080841064)\n",
            "('big', 0.3384079933166504)\n",
            "('funny', 0.33056941628456116)\n",
            "('hard', 0.3305012583732605)\n",
            "('tempting', 0.31914812326431274)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "NQJC4RcYfTQw"
      },
      "cell_type": "markdown",
      "source": [
        "# **Word2Vec Weights onto Keras**\n",
        "\n",
        "Because we are going to use Keras to train an RNN, here is how to extract the actual pretrained weights of the word embedding which can be used for the neural network."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ouLu8Z-Ja4x6",
        "outputId": "a63f8d7a-08a7-4cdb-cf42-374ee3884197",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding\n",
        "\n",
        "pretrained_weights_Bad = model_Bad.wv.vectors \n",
        "pretrained_weights_Good = model_Good.wv.vectors\n",
        "\n",
        "embeddingBad = model_Bad.wv.get_keras_embedding()\n",
        "\n",
        "embeddingGood = model_Good.wv.get_keras_embedding()\n",
        "\n",
        "print(pretrained_weights_Bad)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[ 1.25372    -1.2052641  -0.25990063 ... -0.976092    1.8551047\n",
            "   1.3307298 ]\n",
            " [ 1.4823085  -1.2304381  -0.9231364  ... -1.6590116   1.3164423\n",
            "   0.8863562 ]\n",
            " [ 2.0804706  -0.7694774   0.17020172 ... -0.5701194   1.6237695\n",
            "   1.2792978 ]\n",
            " ...\n",
            " [ 0.6441616   0.12467387  0.17375445 ...  0.27845207  0.394679\n",
            "  -0.18595086]\n",
            " [ 0.70862037  0.14693536  0.24079292 ...  0.2610408   0.41543\n",
            "  -0.17618927]\n",
            " [-0.08563908  0.16787037 -0.30501494 ...  0.32231143  0.14400984\n",
            "   0.1407564 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "GwiBPHfmqBAA"
      },
      "cell_type": "markdown",
      "source": [
        "# LSTM Neural Network\n",
        "\n",
        "Here, we design the architecture for the neural network. You will want to tinker with this to get something that trains in a reasonable number of time, but has good performance."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "SKGPGSQTCl5C",
        "outputId": "17af73df-a129-45e9-bd11-f4254cf69bda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense, Bidirectional, Dropout\n",
        "from keras.layers import LSTM\n",
        "\n",
        "vocab_size, emdedding_size = pretrained_weights_Bad.shape\n",
        "vocab_size_g, embedding_size_g = pretrained_weights_Good.shape\n",
        "\n",
        "# This is where you define the models for the bad movie neural net, and the good movie neural net.\n",
        "# It is important that the models are seperate so you don't fit the model to both datasets.\n",
        "# For consistency's sake, make sure both models have same parameters\n",
        "def get_bad_movie_model():\n",
        "  model = Sequential()\n",
        "  model.add(embeddingBad)\n",
        "  model.add(Bidirectional(LSTM(units=128))) # If you want a non-bidirectional LSTM, just remove the Bidirectional()\n",
        "                                            # Bidirectional significantly increases the training time, especially if \n",
        "                                            # you increase layers/units\n",
        "  model.add(Dropout(rate=0.5)) # Kind of high, but important to avoid overfitting.\n",
        "  model.add(Dense(units=vocab_size))\n",
        "  model.add(Activation('softmax'))\n",
        "  print(model.summary())\n",
        "  return model\n",
        "\n",
        "\n",
        "def get_good_movie_model():\n",
        "  model = Sequential()\n",
        "  model.add(embeddingGood)\n",
        "  model.add(Bidirectional(LSTM(units=128)))\n",
        "  model.add(Dropout(rate=0.5))\n",
        "  model.add(Dense(units=vocab_size_g))\n",
        "  model.add(Activation('softmax'))\n",
        "  print(model.summary())\n",
        "  return model\n",
        "\n",
        "bad_model = get_bad_movie_model()\n",
        "good_model = get_good_movie_model()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 300)         8851200   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 256)               439296    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 29504)             7582528   \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 29504)             0         \n",
            "=================================================================\n",
            "Total params: 16,873,024\n",
            "Trainable params: 8,021,824\n",
            "Non-trainable params: 8,851,200\n",
            "_________________________________________________________________\n",
            "None\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 300)         9127800   \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 256)               439296    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 30426)             7819482   \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 30426)             0         \n",
            "=================================================================\n",
            "Total params: 17,386,578\n",
            "Trainable params: 8,258,778\n",
            "Non-trainable params: 9,127,800\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_F9vn1H6luee",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Splitting the Training and Test Sets"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5Se5ALUkdwJd",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "MAX_SEQ_LEN = 200\n",
        "\n",
        "np.random.seed(42) # Seed needs to be set for consistent results, as otherwise the training/test set change every run.\n",
        "rand_b = np.random.permutation(len(badSentences))\n",
        "rand_g = np.random.permutation(len(goodSentences))\n",
        "\n",
        "bad_sentence_array = np.zeros((len(badSentences), MAX_SEQ_LEN), dtype=np.int32)\n",
        "good_sentence_array = np.zeros((len(goodSentences), MAX_SEQ_LEN), dtype=np.int32)\n",
        "\n",
        "next_word_bad = np.zeros((len(bad_sentence_array)), dtype=np.int32)\n",
        "next_word_good = np.zeros((len(good_sentence_array)), dtype=np.int32)\n",
        "# 0 index in wv.index2word is '.', indicating end of sentence.\n",
        "\n",
        "for s, sentence in enumerate(badSentences):\n",
        "    for w, word in enumerate(sentence):\n",
        "        if w >= MAX_SEQ_LEN:\n",
        "            break\n",
        "        if w < len(sentence)-2:\n",
        "            bad_sentence_array[s][w] = model_Bad.wv.vocab[word].index\n",
        "        else:\n",
        "            next_word_bad[s] = model_Bad.wv.vocab[word].index  \n",
        "            break\n",
        "\n",
        "for s, sentence in enumerate(goodSentences):\n",
        "    for w, word in enumerate(sentence):\n",
        "        if w >= MAX_SEQ_LEN:\n",
        "            break\n",
        "        if w < len(sentence)-2:\n",
        "            good_sentence_array[s][w] = model_Good.wv.vocab[word].index\n",
        "        else:\n",
        "            next_word_good[s] = model_Good.wv.vocab[word].index\n",
        "            break\n",
        "\n",
        "bad_sentence_array = bad_sentence_array[rand_b]\n",
        "next_word_bad = next_word_bad[rand_b]\n",
        "good_sentence_array = good_sentence_array[rand_g]\n",
        "next_word_good = next_word_good[rand_g]\n",
        "\n",
        "train_x = bad_sentence_array[:int(0.8 * len(bad_sentence_array))]\n",
        "train_y = next_word_bad[:int(0.8 * len(next_word_bad))]\n",
        "train_x_good = good_sentence_array[:int(0.8 * len(good_sentence_array))]\n",
        "train_y_good = next_word_good[:int(0.8 * len(next_word_good))]\n",
        "\n",
        "test_x = bad_sentence_array[int(0.8 * len(bad_sentence_array)):]\n",
        "test_y = next_word_bad[int(0.8 * len(next_word_bad)):]\n",
        "test_x_good = good_sentence_array[int(0.8 * len(good_sentence_array)):]\n",
        "test_y_good = next_word_good[int(0.8 * len(next_word_good)):]\n",
        "\n",
        "bad_sentence_array = None\n",
        "good_sentence_array = None\n",
        "next_word_bad = None\n",
        "next_word_good = None\n",
        "# Memory is limited, and all of these are quite large.\n",
        "# Need them to be GCed.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4YUMlFcqmWGW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Callbacks\n",
        "\n",
        "This cell sets up the callbacks for early stopping and saving checkpoints to Google Drive. Makes use of the callback implemented in [this](https://github.com/Zahlii/colab-tf-utils) repository, as due to the way Google Colab works, there is not a way to natively save model checkpoints during training and be able to retrieve them later."
      ]
    },
    {
      "metadata": {
        "id": "N3VlAd8o9L6V",
        "colab_type": "code",
        "outputId": "d184dfe2-c82f-46dc-f1ca-9c2271d52458",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/Zahlii/colab-tf-utils/master/utils.py\n",
        "import utils\n",
        "import os\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "def compare(best, new):\n",
        "  if not best.losses['val_acc']:\n",
        "    print(\"Not best\")\n",
        "  if not new.losses['val_acc']:\n",
        "    print(\"Not new\")\n",
        "  return best.losses['val_acc'] < new.losses['val_acc']\n",
        "\n",
        "def path_b(new):\n",
        "  if new.losses['val_acc'] > 0.20:\n",
        "    return 'bad_movie_model_%s.h5' % new.losses['val_acc']\n",
        "\n",
        "def path_g(new):\n",
        "    if new.losses['val_acc'] > 0.20:\n",
        "        return 'good_movie_model_%s.h5' % new.losses['val_acc']\n",
        "\n",
        "early_stop_b = EarlyStopping(monitor='val_acc', patience=5, verbose=1)\n",
        "early_stop_g = EarlyStopping(monitor='val_acc', patience=5, verbose=1)\n",
        "\n",
        "cb_b = [\n",
        "    utils.GDriveCheckpointer(compare,path_b),\n",
        "    keras.callbacks.TensorBoard(log_dir=os.path.join(utils.LOG_DIR,'bad_movie_model')),\n",
        "    early_stop_b\n",
        "]\n",
        "\n",
        "cb_g = [\n",
        "    utils.GDriveCheckpointer(compare,path_g),\n",
        "    keras.callbacks.TensorBoard(log_dir=os.path.join(utils.LOG_DIR,'good_movie_model')),\n",
        "    early_stop_g\n",
        "]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-12-19 00:28:58--  https://raw.githubusercontent.com/Zahlii/colab-tf-utils/master/utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6935 (6.8K) [text/plain]\n",
            "Saving to: ‘utils.py.5’\n",
            "\n",
            "\rutils.py.5            0%[                    ]       0  --.-KB/s               \rutils.py.5          100%[===================>]   6.77K  --.-KB/s    in 0s      \n",
            "\n",
            "2018-12-19 00:28:58 (71.4 MB/s) - ‘utils.py.5’ saved [6935/6935]\n",
            "\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.11.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.14.6)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.6)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "--2018-12-19 00:29:04--  https://raw.githubusercontent.com/mixuala/colab_utils/master/tboard.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5214 (5.1K) [text/plain]\n",
            "Saving to: ‘tboard.py’\n",
            "\n",
            "tboard.py           100%[===================>]   5.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2018-12-19 00:29:04 (43.8 MB/s) - ‘tboard.py’ saved [5214/5214]\n",
            "\n",
            "ngrok installed\n",
            "status: tensorboard=True, ngrok=True\n",
            "tensorboard url= http://1375783f.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OQrPtHkBp23X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training the Neural Network\n",
        "\n",
        "\n",
        "###Note\n",
        "For loading checkpoints, you will want to get the file ID of the file you want to download. For example, if my checkpoint's url is https://drive.google.com/file/d/abcd1234\n",
        "\n",
        "The id is **abcd1234**\n",
        "\n",
        "To get the URL for the specific file, you just need to right click it and select 'Get Shareable Link'"
      ]
    },
    {
      "metadata": {
        "id": "U1kwiIYtG44W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This is needed to make sure we are still authenticated and don't throw an Exception when we try to upload/download to Drive\n",
        "from google.colab import files\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# CHANGE THESE IF YOU ARE RESUMING TRAINING FROM A CERTAIN EPOCH.\n",
        "BAD_MOVIE_INIT_EPOCH = 0\n",
        "GOOD_MOVIE_INIT_EPOCH = 0\n",
        "\n",
        "# CODE BLOCK FOR LOADING THE MODEL FROM AN EXISTING SAVED MODEL\n",
        "# UNCOMMENT THIS IF YOU ARE LOADING A MODEL FROM A CHECKPOINT TO CONTINUE TRAINING\n",
        "###################################################################\n",
        "# from keras.models import load_model\n",
        "# drive_chk_bad = drive.CreateFile({'id': 'ID_GOES_HERE'})\n",
        "# drive_chk_bad.GetContentFile('chkpt_bad.h5')\n",
        "# drive_chk_good = drive.CreateFile({'id': 'ID_GOES_HERE'})\n",
        "# drive_chk_good.GetContentFile('chkpt_good.h5')\n",
        "\n",
        "# bad_model = load_model('chkpt_bad.h5')\n",
        "# good_model = load_model('chkpt_good.h5')\n",
        "###################################################################\n",
        "# Since these models are checkpoints, they still need to be compiled. So keep the lines directly below.\n",
        "\n",
        "# compile model\n",
        "good_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "bad_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# fit model\n",
        "bad_model.fit(train_x, train_y, validation_split = 0.1, batch_size=128, epochs=50, callbacks=cb_b,\n",
        "             initial_epoch = BAD_MOVIE_INIT_EPOCH) \n",
        "# save the model to file\n",
        "bad_model.save('bad_movie_model.h5')\n",
        "\n",
        "# Re-authenticate, because there is a good chance you will no longer be authenticated after training the model\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# files.download('bad_movie_model.h5')\n",
        "# Uncomment if you want it to download the model to your local machine after training\n",
        "\n",
        "# Save file to Drive\n",
        "b_file = drive.CreateFile()\n",
        "b_file.SetContentFile('bad_movie_model.h5')\n",
        "b_file.Upload()\n",
        "\n",
        "\n",
        "#repeat but for good movies\n",
        "good_model.fit(train_x_good, train_y_good, validation_split = 0.1, batch_size=128, epochs=50, callbacks=cb_g,\n",
        "              initial_epoch = GOOD_MOVIE_INIT_EPOCH)\n",
        "good_model.save('good_movie_model.h5')\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# files.download('good_movie_model.h5')\n",
        "# Uncomment if you want to download the model to your local machine after training\n",
        "\n",
        "g_file = drive.CreateFile()\n",
        "g_file.SetContentFile('good_movie_model.h5')\n",
        "g_file.Upload()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f0YhwvUsBhqu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Error Analysis Section\n",
        "\n",
        "Includes calculation for perplexity, predicted words for a subset of the test set, and sentence generation."
      ]
    },
    {
      "metadata": {
        "id": "2ypOX4caDeha",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Loading Model\n",
        "In case we don't want to run the cell above, and have a trained model we just want to load."
      ]
    },
    {
      "metadata": {
        "id": "6OTrwiK2DdXY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The IDs left there are for the copy of the final model saved to Leo's Google Drive.\n",
        "from keras.models import load_model\n",
        "drive_file_bad = drive.CreateFile({'id': '1eZat2inYSL2nSOOYW1dkU3tSK0S1Ex5o'})\n",
        "drive_file_bad.GetContentFile('mdl_bad.h5')\n",
        "drive_file_good = drive.CreateFile({'id': '1yyCarcA3OFSy9vNB2ofon5T2jqmA7LvE'})\n",
        "drive_file_good.GetContentFile('mdl_good.h5')\n",
        "\n",
        "bad_model = load_model('mdl_bad.h5')\n",
        "good_model = load_model('mdl_good.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S3qYPja8B3Md",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Cross-Entropy and Perplexity"
      ]
    },
    {
      "metadata": {
        "id": "DdBPChBQox_9",
        "colab_type": "code",
        "outputId": "f3cb207d-cab5-4032-d749-2269b2cfa24b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.losses import sparse_categorical_crossentropy\n",
        "from keras.backend import pow, constant, eval, mean\n",
        "\n",
        "bad_movie_samples = test_x.shape[0]\n",
        "good_movie_samples = test_x_good.shape[0]\n",
        "SCALE_FACTOR = 5 # Proportion of test set used for perplexity calculation = 1 / SCALE_FACTOR\n",
        "print(\"Amount of bad movie lines tested: \", bad_movie_samples // SCALE_FACTOR)\n",
        "print(\"Amount of good movie lines tested: \", good_movie_samples // SCALE_FACTOR)\n",
        "\n",
        "\n",
        "# This block can be a bit slow and very memory-hungry.\n",
        "#############################################\n",
        "# Predict for approximately 20% of the test set. Using too much tends to result in the Colab VM running out of memory and crashing.\n",
        "# Although it's a bit inconsistent, since Colab VMs do not always have the same amount of memory available.\n",
        "# Anything smaller than 4 for the scale factor usually crashes, 4 will sometimes crash as well. 5 is generally safe.\n",
        "preds_bad = constant(bad_model.predict(test_x[:bad_movie_samples // SCALE_FACTOR]))\n",
        "preds_good = constant(good_model.predict(test_x_good[:good_movie_samples // SCALE_FACTOR]))\n",
        "\n",
        "#Cross-entropy on movie lines\n",
        "cx_b = mean(sparse_categorical_crossentropy(test_y[:bad_movie_samples // SCALE_FACTOR], preds_bad))\n",
        "cx_g = mean(sparse_categorical_crossentropy(test_y_good[:good_movie_samples // SCALE_FACTOR], preds_good))\n",
        "##############################################\n",
        "\n",
        "\n",
        "perplexity_b = pow(2.0, cx_b)\n",
        "perplexity_g = pow(2.0, cx_g)\n",
        "\n",
        "\n",
        "print(\"Perplexity of bad movie model on bad movie lines: \", eval(perplexity_b))\n",
        "print(\"Perplexity of good movie model on good movie lines: \", eval(perplexity_g))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Amount of bad movie lines tested:  3684\n",
            "Amount of good movie lines tested:  5009\n",
            "Perplexity of bad movie model on bad movie lines:  111.54793\n",
            "Perplexity of good movie model on good movie lines:  106.30434\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hi8wEefQVL7x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Predicting Next Word of Sentence\n",
        "In this section, for the first 100 sentences in both the good movie and bad movie test sets, we have the respective model predict what the next word should be, and compare it to the actual word that occurs.\n",
        "\n",
        "After doing so, we then show what sentence was input to the model, and what word it produced as well as what the ground truth was."
      ]
    },
    {
      "metadata": {
        "id": "XUH75ux51C7a",
        "colab_type": "code",
        "outputId": "fc1a0ff7-dc97-40df-8c13-cc66e4fe8ad0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 14643
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.backend import argmax\n",
        "sentence_arr = test_x[0]\n",
        "# print(model_Bad.wv.index2word[eval(argmax(preds_bad[0]))])\n",
        "\n",
        "print(\"------Bad Movie Model------\")\n",
        "for i, sentence in enumerate(test_x[0:100]):\n",
        "    str_build = \"\"\n",
        "    for word in sentence:\n",
        "        if word == 0:\n",
        "            break\n",
        "        str_build += model_Bad.wv.index2word[word]\n",
        "        str_build += \" \"\n",
        "    print(\"Starting string: '\" + str_build + \"'\")\n",
        "    prediction = model_Bad.wv.index2word[eval(argmax(preds_bad[i]))]\n",
        "    print(\"Predicted end word: '\" + prediction + \"'\")\n",
        "    print(\"Actual end word: '\" + model_Bad.wv.index2word[test_y[i]] + \"'\\n\")\n",
        "\n",
        "print(\"\\n\\n------Good Movie Model------\")\n",
        "for i, sentence in enumerate(test_x_good[0:100]):\n",
        "    str_build = \"\"\n",
        "    for word in sentence:\n",
        "        if word == 0:\n",
        "            break\n",
        "        str_build += model_Good.wv.index2word[word]\n",
        "        str_build += \" \"\n",
        "    print(\"Starting string: '\" + str_build + \"'\")\n",
        "    prediction = model_Good.wv.index2word[eval(argmax(preds_good[i]))]\n",
        "    print(\"Predicted end word: '\" + prediction + \"'\")\n",
        "    print(\"Actual end word: '\" + model_Good.wv.index2word[test_y[i]] + \"'\\n\")"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------Bad Movie Model------\n",
            "Starting string: 'maintain '\n",
            "Predicted end word: 'it'\n",
            "Actual end word: 'perimeter'\n",
            "\n",
            "Starting string: ''\n",
            "Predicted end word: '.'\n",
            "Actual end word: '.'\n",
            "\n",
            "Starting string: 'i got '\n",
            "Predicted end word: 'it'\n",
            "Actual end word: 'it'\n",
            "\n",
            "Starting string: 'yeah , '\n",
            "Predicted end word: 'yeah'\n",
            "Actual end word: 'mike'\n",
            "\n",
            "Starting string: 'why did n't you tell '\n",
            "Predicted end word: 'me'\n",
            "Actual end word: 'me'\n",
            "\n",
            "Starting string: 'you 'll have to climb the ice pillar and get '\n",
            "Predicted end word: 'it'\n",
            "Actual end word: 'it'\n",
            "\n",
            "Starting string: 'jane , there is no '\n",
            "Predicted end word: 'choice'\n",
            "Actual end word: 'curse'\n",
            "\n",
            "Starting string: 'but for me it was '\n",
            "Predicted end word: 'it'\n",
            "Actual end word: 'tuesday'\n",
            "\n",
            "Starting string: 'why are you '\n",
            "Predicted end word: 'stopa'\n",
            "Actual end word: 'stalling'\n",
            "\n",
            "Starting string: 'you are on the verge of destroying the entire '\n",
            "Predicted end word: 'world'\n",
            "Actual end word: 'universe'\n",
            "\n",
            "Starting string: 'whichever crew wins today , you 're gon na wan na remember their faces because the next time you 'll see them will be lil ' ~kim 's new '\n",
            "Predicted end word: 'york'\n",
            "Actual end word: 'video'\n",
            "\n",
            "Starting string: 'come on , '\n",
            "Predicted end word: 'baby'\n",
            "Actual end word: 'y'all'\n",
            "\n",
            "Starting string: 'johnny fucks lisa ’ s belly '\n",
            "Predicted end word: 'down'\n",
            "Actual end word: 'button'\n",
            "\n",
            "Starting string: 'so if something looks familiar , heads '\n",
            "Predicted end word: 'up'\n",
            "Actual end word: 'up'\n",
            "\n",
            "Starting string: 'uh actually i like '\n",
            "Predicted end word: 'that'\n",
            "Actual end word: 'popcorn'\n",
            "\n",
            "Starting string: 'yes , sir , mr. '\n",
            "Predicted end word: 'black'\n",
            "Actual end word: 'johnson'\n",
            "\n",
            "Starting string: 'frederick '\n",
            "Predicted end word: 'you'\n",
            "Actual end word: 'flintstone'\n",
            "\n",
            "Starting string: ''\n",
            "Predicted end word: '.'\n",
            "Actual end word: 'whatever'\n",
            "\n",
            "Starting string: 'batgirl those targeting mirrors are '\n",
            "Predicted end word: 'batgirl'\n",
            "Actual end word: 'frozen'\n",
            "\n",
            "Starting string: '330 ivy presses a button and the door slides '\n",
            "Predicted end word: 'open'\n",
            "Actual end word: 'open'\n",
            "\n",
            "Starting string: 'you 're writing a little story , '\n",
            "Predicted end word: 'right'\n",
            "Actual end word: 'huh'\n",
            "\n",
            "Starting string: 'you stole my good '\n",
            "Predicted end word: 'shot'\n",
            "Actual end word: 'pair'\n",
            "\n",
            "Starting string: 'i think i broke my other '\n",
            "Predicted end word: 'fin'\n",
            "Actual end word: 'arm'\n",
            "\n",
            "Starting string: ''\n",
            "Predicted end word: '.'\n",
            "Actual end word: 'amy'\n",
            "\n",
            "Starting string: 'i 'm '\n",
            "Predicted end word: 'sorry'\n",
            "Actual end word: 'carlos'\n",
            "\n",
            "Starting string: ''\n",
            "Predicted end word: '.'\n",
            "Actual end word: 'hi'\n",
            "\n",
            "Starting string: '426 00:24:06,600 00:24:10,092 oh , '\n",
            "Predicted end word: 'yeah'\n",
            "Actual end word: 'yeah'\n",
            "\n",
            "Starting string: 'wilma '\n",
            "Predicted end word: 'is'\n",
            "Actual end word: 'slaghoople'\n",
            "\n",
            "Starting string: ''\n",
            "Predicted end word: '.'\n",
            "Actual end word: 'yeah'\n",
            "\n",
            "Starting string: 'why are you ignoring '\n",
            "Predicted end word: 'me'\n",
            "Actual end word: 'me'\n",
            "\n",
            "Starting string: 'no , i 'm not telling '\n",
            "Predicted end word: 'you'\n",
            "Actual end word: 'you'\n",
            "\n",
            "Starting string: 'this should cheer us '\n",
            "Predicted end word: 'up'\n",
            "Actual end word: 'up'\n",
            "\n",
            "Starting string: 'in their wake a hundred doubletakes , astonished '\n",
            "Predicted end word: 'vampires'\n",
            "Actual end word: 'glances'\n",
            "\n",
            "Starting string: ''\n",
            "Predicted end word: '.'\n",
            "Actual end word: '.'\n",
            "\n",
            "Starting string: 'listen , max what matters now is you and your mom can move on with your '\n",
            "Predicted end word: 'mouth'\n",
            "Actual end word: 'lives'\n",
            "\n",
            "Starting string: 'captain callahan , 511. sergeant jones , 513. sergeant tackleberry , 514. cadet connors , 520. captain harris , 515. not exactly a fourstar hotel , is '\n",
            "Predicted end word: 'it'\n",
            "Actual end word: 'it'\n",
            "\n",
            "Starting string: 'i '\n",
            "Predicted end word: 'know'\n",
            "Actual end word: 'know'\n",
            "\n",
            "Starting string: 'you know what happens '\n",
            "Predicted end word: 'now'\n",
            "Actual end word: 'now'\n",
            "\n",
            "Starting string: 'get off of '\n",
            "Predicted end word: 'me'\n",
            "Actual end word: 'me'\n",
            "\n",
            "Starting string: 'what just '\n",
            "Predicted end word: 'happened'\n",
            "Actual end word: 'happened'\n",
            "\n",
            "Starting string: 'let 's '\n",
            "Predicted end word: 'go'\n",
            "Actual end word: 'go'\n",
            "\n",
            "Starting string: 'i can ’ t wait till '\n",
            "Predicted end word: 'now'\n",
            "Actual end word: 'later'\n",
            "\n",
            "Starting string: ''\n",
            "Predicted end word: '.'\n",
            "Actual end word: 'please'\n",
            "\n",
            "Starting string: 'his only facebook friend is mel '\n",
            "Predicted end word: 'open'\n",
            "Actual end word: 'gibson'\n",
            "\n",
            "Starting string: 'mmm , yeah , he '\n",
            "Predicted end word: 'is'\n",
            "Actual end word: 'did'\n",
            "\n",
            "Starting string: 'you 're lucky you even in the '\n",
            "Predicted end word: 'world'\n",
            "Actual end word: 'avengers'\n",
            "\n",
            "Starting string: 'i hope it never '\n",
            "Predicted end word: 'have'\n",
            "Actual end word: 'ends'\n",
            "\n",
            "Starting string: 'good '\n",
            "Predicted end word: 'luck'\n",
            "Actual end word: 'evening'\n",
            "\n",
            "Starting string: 'a handsome bouncer stands '\n",
            "Predicted end word: 'out'\n",
            "Actual end word: 'guard'\n",
            "\n",
            "Starting string: 'keep '\n",
            "Predicted end word: 'trying'\n",
            "Actual end word: 'looking'\n",
            "\n",
            "Starting string: 'she wants to torture you , for what you did to '\n",
            "Predicted end word: 'do'\n",
            "Actual end word: 'jack'\n",
            "\n",
            "Starting string: 'we got ta get these computers checked '\n",
            "Predicted end word: 'out'\n",
            "Actual end word: 'out'\n",
            "\n",
            "Starting string: ''\n",
            "Predicted end word: '.'\n",
            "Actual end word: 'what'\n",
            "\n",
            "Starting string: 'you 're '\n",
            "Predicted end word: 'right'\n",
            "Actual end word: 'right'\n",
            "\n",
            "Starting string: 'no , i 'm going '\n",
            "Predicted end word: 'on'\n",
            "Actual end word: 'home'\n",
            "\n",
            "Starting string: 'be '\n",
            "Predicted end word: 'careful'\n",
            "Actual end word: 'proud'\n",
            "\n",
            "Starting string: 'why did n't you say you wanted him in the first '\n",
            "Predicted end word: 'day'\n",
            "Actual end word: 'place'\n",
            "\n",
            "Starting string: 'yeah , for a little '\n",
            "Predicted end word: 'bit'\n",
            "Actual end word: 'bit'\n",
            "\n",
            "Starting string: 'patience 'miracle ingredient in beaunique just a drop makes wrinkles vanish , blah blah blah ' but what is '\n",
            "Predicted end word: 'out'\n",
            "Actual end word: 'it'\n",
            "\n",
            "Starting string: 'i have n't touched your '\n",
            "Predicted end word: 'feelings'\n",
            "Actual end word: 'seat'\n",
            "\n",
            "Starting string: '30 freeze is racing towards the altar and his fallen '\n",
            "Predicted end word: 'place'\n",
            "Actual end word: 'gun'\n",
            "\n",
            "Starting string: 'he did n't come '\n",
            "Predicted end word: 'on'\n",
            "Actual end word: 'up'\n",
            "\n",
            "Starting string: 'let 's have a '\n",
            "Predicted end word: 'toast'\n",
            "Actual end word: 'party'\n",
            "\n",
            "Starting string: ''\n",
            "Predicted end word: '.'\n",
            "Actual end word: 'girlfriend'\n",
            "\n",
            "Starting string: 'passed '\n",
            "Predicted end word: 'it'\n",
            "Actual end word: 'away'\n",
            "\n",
            "Starting string: 'everyone exits '\n",
            "Predicted end word: 'on'\n",
            "Actual end word: 'enthusiastically'\n",
            "\n",
            "Starting string: 'he 's out there '\n",
            "Predicted end word: 'back'\n",
            "Actual end word: 'somewhere'\n",
            "\n",
            "Starting string: 'it 's 8:30 in the morning , my '\n",
            "Predicted end word: 'baby'\n",
            "Actual end word: 'time'\n",
            "\n",
            "Starting string: 'thank '\n",
            "Predicted end word: 'you'\n",
            "Actual end word: 'you'\n",
            "\n",
            "Starting string: 'how could you do that to '\n",
            "Predicted end word: 'happen'\n",
            "Actual end word: 'me'\n",
            "\n",
            "Starting string: '943 00:50:22,266 00:50:23,699 big '\n",
            "Predicted end word: 'time'\n",
            "Actual end word: 'time'\n",
            "\n",
            "Starting string: 'that would really be a spectacular '\n",
            "Predicted end word: 'thing'\n",
            "Actual end word: 'event'\n",
            "\n",
            "Starting string: 'with all due respect , mr cummings , he was the president of united states an unfortunate accident and besides , i cant stand the wife denied '\n",
            "Predicted end word: 'what'\n",
            "Actual end word: 'next'\n",
            "\n",
            "Starting string: 'it 's all very dark in '\n",
            "Predicted end word: 'here'\n",
            "Actual end word: 'there'\n",
            "\n",
            "Starting string: 'you get a plus for being the first hand in the '\n",
            "Predicted end word: 'house'\n",
            "Actual end word: 'air'\n",
            "\n",
            "Starting string: 'you know , there 's that little village not too far from '\n",
            "Predicted end word: 'her'\n",
            "Actual end word: 'here'\n",
            "\n",
            "Starting string: ''\n",
            "Predicted end word: '.'\n",
            "Actual end word: 'oh'\n",
            "\n",
            "Starting string: 'work your whole bicuspids area , your whole bilaterals and '\n",
            "Predicted end word: 'paper'\n",
            "Actual end word: 'bisexuals'\n",
            "\n",
            "Starting string: 'sorry , mrs. '\n",
            "Predicted end word: 'trent'\n",
            "Actual end word: 'peacock'\n",
            "\n",
            "Starting string: 'this is n't very good '\n",
            "Predicted end word: 'one'\n",
            "Actual end word: 'food'\n",
            "\n",
            "Starting string: 'take this '\n",
            "Predicted end word: 'out'\n",
            "Actual end word: 'man'\n",
            "\n",
            "Starting string: 'they 've been acting strange for '\n",
            "Predicted end word: 'us'\n",
            "Actual end word: 'days'\n",
            "\n",
            "Starting string: ''' oh , that 's '\n",
            "Predicted end word: 'it'\n",
            "Actual end word: 'rich'\n",
            "\n",
            "Starting string: 'maybe there 's like a priest inside who can help '\n",
            "Predicted end word: 'me'\n",
            "Actual end word: 'us'\n",
            "\n",
            "Starting string: ''\n",
            "Predicted end word: '.'\n",
            "Actual end word: 'hey'\n",
            "\n",
            "Starting string: 'that was just the amuse '\n",
            "Predicted end word: 'thing'\n",
            "Actual end word: 'bouche'\n",
            "\n",
            "Starting string: 'it belongs to the guardian of the good '\n",
            "Predicted end word: 'time'\n",
            "Actual end word: 'lmoogi'\n",
            "\n",
            "Starting string: ''\n",
            "Predicted end word: '.'\n",
            "Actual end word: 'piease'\n",
            "\n",
            "Starting string: ''\n",
            "Predicted end word: '.'\n",
            "Actual end word: 'everyone'\n",
            "\n",
            "Starting string: '534 '\n",
            "Predicted end word: 'int'\n",
            "Actual end word: 'int'\n",
            "\n",
            "Starting string: ''\n",
            "Predicted end word: '.'\n",
            "Actual end word: 'larry'\n",
            "\n",
            "Starting string: 'she 's like the ones at the '\n",
            "Predicted end word: 'hand'\n",
            "Actual end word: 'baywatch'\n",
            "\n",
            "Starting string: 'it 's '\n",
            "Predicted end word: 'okay'\n",
            "Actual end word: 'real'\n",
            "\n",
            "Starting string: 'what do you '\n",
            "Predicted end word: 'mean'\n",
            "Actual end word: 'want'\n",
            "\n",
            "Starting string: 'crime 's worst '\n",
            "Predicted end word: 'thing'\n",
            "Actual end word: 'nightmare'\n",
            "\n",
            "Starting string: 'are you planning to tie the '\n",
            "Predicted end word: 'phone'\n",
            "Actual end word: 'knot'\n",
            "\n",
            "Starting string: ''\n",
            "Predicted end word: '.'\n",
            "Actual end word: 'ooh'\n",
            "\n",
            "Starting string: 'no , if you 'll join forces with me , together we can make the world safe for war profits '\n",
            "Predicted end word: 'gals'\n",
            "Actual end word: 'again'\n",
            "\n",
            "Starting string: 'there 's some good '\n",
            "Predicted end word: 'idea'\n",
            "Actual end word: 'news'\n",
            "\n",
            "Starting string: '[ door closes ] oh , '\n",
            "Predicted end word: 'psst'\n",
            "Actual end word: 'jesus'\n",
            "\n",
            "\n",
            "\n",
            "------Good Movie Model------\n",
            "Starting string: ''\n",
            "Predicted end word: '.'\n",
            "Actual end word: 'owner'\n",
            "\n",
            "Starting string: 'then there was a case of a guy who was found '\n",
            "Predicted end word: 'it'\n",
            "Actual end word: '.'\n",
            "\n",
            "Starting string: 'we can not '\n",
            "Predicted end word: 'return'\n",
            "Actual end word: 'it'\n",
            "\n",
            "Starting string: 'get over '\n",
            "Predicted end word: 'here'\n",
            "Actual end word: 'happen'\n",
            "\n",
            "Starting string: 'you 're out early because i got you a '\n",
            "Predicted end word: 'favor'\n",
            "Actual end word: 'we'\n",
            "\n",
            "Starting string: 'we 'll sleep real '\n",
            "Predicted end word: 'time'\n",
            "Actual end word: 'it'\n",
            "\n",
            "Starting string: 'phyllis , do you mind if we do n't finish this '\n",
            "Predicted end word: 'day'\n",
            "Actual end word: 'victory'\n",
            "\n",
            "Starting string: 'we was like peas and carrots '\n",
            "Predicted end word: 'again'\n",
            "Actual end word: 'within'\n",
            "\n",
            "Starting string: 'twentyfive pounds i '\n",
            "Predicted end word: 'got'\n",
            "Actual end word: 'suicidal'\n",
            "\n",
            "Starting string: 'maximum '\n",
            "Predicted end word: 'stern'\n",
            "Actual end word: 'serve'\n",
            "\n",
            "Starting string: 'from the landward side , there are no guns at '\n",
            "Predicted end word: 'you'\n",
            "Actual end word: 'm.l.s'\n",
            "\n",
            "Starting string: 'cobb , i will still honor the '\n",
            "Predicted end word: 'letter'\n",
            "Actual end word: 'walks'\n",
            "\n",
            "Starting string: 'he says you 're smart , you 're loyal and you 're not a '\n",
            "Predicted end word: 'teacher'\n",
            "Actual end word: 'card'\n",
            "\n",
            "Starting string: ''\n",
            "Predicted end word: '.'\n",
            "Actual end word: 'up'\n",
            "\n",
            "Starting string: ''\n",
            "Predicted end word: '.'\n",
            "Actual end word: 'millions'\n",
            "\n",
            "Starting string: ''\n",
            "Predicted end word: '.'\n",
            "Actual end word: 'armed'\n",
            "\n",
            "Starting string: ''\n",
            "Predicted end word: '.'\n",
            "Actual end word: 'howard'\n",
            "\n",
            "Starting string: 'here is a good '\n",
            "Predicted end word: 'one'\n",
            "Actual end word: 'pay'\n",
            "\n",
            "Starting string: 'go on , '\n",
            "Predicted end word: 'man'\n",
            "Actual end word: 'given'\n",
            "\n",
            "Starting string: 'what a ball '\n",
            "Predicted end word: 'game'\n",
            "Actual end word: 'care'\n",
            "\n",
            "Starting string: ''\n",
            "Predicted end word: '.'\n",
            "Actual end word: 'son'\n",
            "\n",
            "Starting string: 'your '\n",
            "Predicted end word: 'name'\n",
            "Actual end word: 'ordinary'\n",
            "\n",
            "Starting string: '[ lt : we 've interrupted you for a very long '\n",
            "Predicted end word: 'time'\n",
            "Actual end word: 'writing'\n",
            "\n",
            "Starting string: 'all '\n",
            "Predicted end word: 'right'\n",
            "Actual end word: 'daesu'\n",
            "\n",
            "Starting string: 'there 's the professor '\n",
            "Predicted end word: 'here'\n",
            "Actual end word: 'rolled'\n",
            "\n",
            "Starting string: ''\n",
            "Predicted end word: '.'\n",
            "Actual end word: 'big'\n",
            "\n",
            "Starting string: 'i 'm a '\n",
            "Predicted end word: 'cop'\n",
            "Actual end word: 'did'\n",
            "\n",
            "Starting string: 'you know what i '\n",
            "Predicted end word: 'mean'\n",
            "Actual end word: 'du'\n",
            "\n",
            "Starting string: ''\n",
            "Predicted end word: '.'\n",
            "Actual end word: 'did'\n",
            "\n",
            "Starting string: 'it 's '\n",
            "Predicted end word: 'beautiful'\n",
            "Actual end word: 'we'\n",
            "\n",
            "Starting string: 'he will not '\n",
            "Predicted end word: 'be'\n",
            "Actual end word: 'you'\n",
            "\n",
            "Starting string: 'skimming across the '\n",
            "Predicted end word: 'street'\n",
            "Actual end word: 'up'\n",
            "\n",
            "Starting string: 'you 'll lose a lot of '\n",
            "Predicted end word: 'money'\n",
            "Actual end word: 'cable'\n",
            "\n",
            "Starting string: 'i took up this profession when i was ten years '\n",
            "Predicted end word: 'ago'\n",
            "Actual end word: '.'\n",
            "\n",
            "Starting string: 'carolyn well , all i know is i love shooting this '\n",
            "Predicted end word: 'kitchen'\n",
            "Actual end word: 'papa'\n",
            "\n",
            "Starting string: 'did you hear what i '\n",
            "Predicted end word: 'said'\n",
            "Actual end word: 'it'\n",
            "\n",
            "Starting string: 'buffalo gals , ca n't you come out '\n",
            "Predicted end word: 'tonight'\n",
            "Actual end word: 'they'\n",
            "\n",
            "Starting string: 'goddamn it , you son of a '\n",
            "Predicted end word: 'bitch'\n",
            "Actual end word: 'right'\n",
            "\n",
            "Starting string: 'it ai n't gon na look too good killing a guy you owe money '\n",
            "Predicted end word: 'anymore'\n",
            "Actual end word: 'we'\n",
            "\n",
            "Starting string: 'that guy 's too '\n",
            "Predicted end word: 'late'\n",
            "Actual end word: 'which'\n",
            "\n",
            "Starting string: 'you read the bible , '\n",
            "Predicted end word: 'brett'\n",
            "Actual end word: 'get'\n",
            "\n",
            "Starting string: 'where shall we start our '\n",
            "Predicted end word: 'policy'\n",
            "Actual end word: 'friends'\n",
            "\n",
            "Starting string: '19. doctor & wendy walk forward along the corridor camera tracks back before them and pans rl with them to living '\n",
            "Predicted end word: 'door'\n",
            "Actual end word: 'l'\n",
            "\n",
            "Starting string: ''\n",
            "Predicted end word: '.'\n",
            "Actual end word: 'sydney'\n",
            "\n",
            "Starting string: 'lt. '\n",
            "Predicted end word: 'down'\n",
            "Actual end word: 'as'\n",
            "\n",
            "Starting string: 'she was a total slut on the outside she acted like a prude but she was a filthy whore on the inside rumors had it that that slut fucked everyone at school i should 've gotten in there i also heard that her family was really rich her grades were good , too but the bad thing was that she was a slut man wow , this is such an old story '\n",
            "Predicted end word: 'it'\n",
            "Actual end word: 'lund'\n",
            "\n",
            "Starting string: 'let 's get you outta here , '\n",
            "Predicted end word: 'man'\n",
            "Actual end word: 'song'\n",
            "\n",
            "Starting string: 'of '\n",
            "Predicted end word: 'course'\n",
            "Actual end word: 'sits'\n",
            "\n",
            "Starting string: ''\n",
            "Predicted end word: '.'\n",
            "Actual end word: 'expect'\n",
            "\n",
            "Starting string: 'do you want a '\n",
            "Predicted end word: 'drink'\n",
            "Actual end word: 'fucking'\n",
            "\n",
            "Starting string: 'i 'm '\n",
            "Predicted end word: 'sorry'\n",
            "Actual end word: 'its'\n",
            "\n",
            "Starting string: 'come on , '\n",
            "Predicted end word: 'man'\n",
            "Actual end word: 'but'\n",
            "\n",
            "Starting string: 'camera tracks back before '\n",
            "Predicted end word: 'him'\n",
            "Actual end word: 'is'\n",
            "\n",
            "Starting string: 'signore salieri , open the door , be good '\n",
            "Predicted end word: 'room'\n",
            "Actual end word: 'out'\n",
            "\n",
            "Starting string: 'he 's '\n",
            "Predicted end word: 'dead'\n",
            "Actual end word: 'find'\n",
            "\n",
            "Starting string: 'why do you linger here when there is no '\n",
            "Predicted end word: 'money'\n",
            "Actual end word: 'south'\n",
            "\n",
            "Starting string: ''\n",
            "Predicted end word: '.'\n",
            "Actual end word: 'kill'\n",
            "\n",
            "Starting string: 'do you love '\n",
            "Predicted end word: 'him'\n",
            "Actual end word: 'ah'\n",
            "\n",
            "Starting string: ''\n",
            "Predicted end word: '.'\n",
            "Actual end word: 'it'\n",
            "\n",
            "Starting string: ''\n",
            "Predicted end word: '.'\n",
            "Actual end word: 'report'\n",
            "\n",
            "Starting string: ''\n",
            "Predicted end word: '.'\n",
            "Actual end word: 'check'\n",
            "\n",
            "Starting string: ''\n",
            "Predicted end word: '.'\n",
            "Actual end word: 'up'\n",
            "\n",
            "Starting string: 'position reports and very faint sos calls from enemy '\n",
            "Predicted end word: 'order'\n",
            "Actual end word: 'watch'\n",
            "\n",
            "Starting string: 'i ca n't have '\n",
            "Predicted end word: 'it'\n",
            "Actual end word: 'situation'\n",
            "\n",
            "Starting string: 'pan it around a '\n",
            "Predicted end word: 'please'\n",
            "Actual end word: 'home'\n",
            "\n",
            "Starting string: 'please , your '\n",
            "Predicted end word: 'grace'\n",
            "Actual end word: 'suggesting'\n",
            "\n",
            "Starting string: 'salvatore carefully observes her graying hair , her blue eyes lined with wrinkles , the somewhat faded beauty mark on her '\n",
            "Predicted end word: 'face'\n",
            "Actual end word: 'enemy'\n",
            "\n",
            "Starting string: 'change to main '\n",
            "Predicted end word: 'light'\n",
            "Actual end word: 'where'\n",
            "\n",
            "Starting string: 'give me the '\n",
            "Predicted end word: 'whip'\n",
            "Actual end word: 'you'\n",
            "\n",
            "Starting string: 'your love of the halfling 's leaf has clearly slowed your '\n",
            "Predicted end word: 'lord'\n",
            "Actual end word: 'we'\n",
            "\n",
            "Starting string: 'she ca n't act , she ca n't sing and she ca n't '\n",
            "Predicted end word: 'know'\n",
            "Actual end word: 'where'\n",
            "\n",
            "Starting string: 'i draw fire '\n",
            "Predicted end word: 'imediately'\n",
            "Actual end word: 'halt'\n",
            "\n",
            "Starting string: 'd'you want to save your wife by doing what i '\n",
            "Predicted end word: 'do'\n",
            "Actual end word: 'heard'\n",
            "\n",
            "Starting string: 'it was very '\n",
            "Predicted end word: 'young'\n",
            "Actual end word: 'his'\n",
            "\n",
            "Starting string: 'come forward '\n",
            "Predicted end word: 'in'\n",
            "Actual end word: 'brother'\n",
            "\n",
            "Starting string: 'halloran glad to meet you , '\n",
            "Predicted end word: 'tony'\n",
            "Actual end word: ''ll'\n",
            "\n",
            "Starting string: 'but i think , mr. frodo , i do '\n",
            "Predicted end word: 'n't'\n",
            "Actual end word: 'here'\n",
            "\n",
            "Starting string: 'by the way , |what are we having for '\n",
            "Predicted end word: 'you'\n",
            "Actual end word: 'heheheee'\n",
            "\n",
            "Starting string: 'it bores me '\n",
            "Predicted end word: 'out'\n",
            "Actual end word: 'grin'\n",
            "\n",
            "Starting string: 'twelve o ' '\n",
            "Predicted end word: 'clock'\n",
            "Actual end word: 'music'\n",
            "\n",
            "Starting string: 'we 'll make a big '\n",
            "Predicted end word: 'deal'\n",
            "Actual end word: 'going'\n",
            "\n",
            "Starting string: 'yes , mr. '\n",
            "Predicted end word: 'kane'\n",
            "Actual end word: 'lt'\n",
            "\n",
            "Starting string: 'lester it 's '\n",
            "Predicted end word: 'okay'\n",
            "Actual end word: 'search'\n",
            "\n",
            "Starting string: 'i wo n't go in the '\n",
            "Predicted end word: 'morning'\n",
            "Actual end word: 'sir'\n",
            "\n",
            "Starting string: 'good '\n",
            "Predicted end word: 'night'\n",
            "Actual end word: 'back'\n",
            "\n",
            "Starting string: ''' `` are you '\n",
            "Predicted end word: 'ready'\n",
            "Actual end word: 'reappears'\n",
            "\n",
            "Starting string: 'not the '\n",
            "Predicted end word: 'way'\n",
            "Actual end word: 'mentioned'\n",
            "\n",
            "Starting string: 'where 's mrs. blaine 's box of '\n",
            "Predicted end word: 'coins'\n",
            "Actual end word: 'solo'\n",
            "\n",
            "Starting string: 'i know what i 'm going to do tomorrow and the next day and next year and the hear after '\n",
            "Predicted end word: 'you'\n",
            "Actual end word: 'without'\n",
            "\n",
            "Starting string: 'we have a new '\n",
            "Predicted end word: 'choice'\n",
            "Actual end word: 'danny'\n",
            "\n",
            "Starting string: 'it 's '\n",
            "Predicted end word: 'beautiful'\n",
            "Actual end word: 'couple'\n",
            "\n",
            "Starting string: 'new guy , you '\n",
            "Predicted end word: 'know'\n",
            "Actual end word: 'killer'\n",
            "\n",
            "Starting string: 'general `` buck '' schmuck he 's been here for almost two hours , and lord knows what he 's '\n",
            "Predicted end word: 'saying'\n",
            "Actual end word: '$'\n",
            "\n",
            "Starting string: 'lloyd lloyd what 'll it be , '\n",
            "Predicted end word: 'yes'\n",
            "Actual end word: 'think'\n",
            "\n",
            "Starting string: 'remember your failure at the '\n",
            "Predicted end word: 'airport'\n",
            "Actual end word: 'wild'\n",
            "\n",
            "Starting string: 'he crosses '\n",
            "Predicted end word: 'me'\n",
            "Actual end word: 'sandwiches'\n",
            "\n",
            "Starting string: ''\n",
            "Predicted end word: '.'\n",
            "Actual end word: 'jane'\n",
            "\n",
            "Starting string: 'their guns will destroy you '\n",
            "Predicted end word: 'now'\n",
            "Actual end word: 'still'\n",
            "\n",
            "Starting string: 'william '\n",
            "Predicted end word: 'wallace'\n",
            "Actual end word: 'mary'\n",
            "\n",
            "Starting string: 'split '\n",
            "Predicted end word: 'up'\n",
            "Actual end word: 'high'\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yS5Qnu76dgVK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Sentence Generation Using Argmax()\n",
        "This section generates sentences given a starting sentence and a sentence length (i.e. maximum number of additional words to generate).\n",
        "\n",
        "It does this by taking the argmax of the prediction given the sentence at each step, and then adding that word to the sentence. Note that a higher max sentence length usually means a longer sentence, as the models don't tend to terminate the sentence early all that often."
      ]
    },
    {
      "metadata": {
        "id": "eKHHmW3B2KdS",
        "colab_type": "code",
        "outputId": "bed2f0f0-bf0b-4cbe-ddcd-77962eb6594f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.backend import sum\n",
        "\n",
        "def word_list_to_array(words, model):\n",
        "    arr = np.zeros((1, MAX_SEQ_LEN), dtype=np.int32)\n",
        "    for i, word in enumerate(words):\n",
        "        arr[0][i] = model.wv.vocab[word].index\n",
        "    return arr\n",
        "\n",
        "def array_to_sentence(arr, model):\n",
        "    sentence = \"\"\n",
        "    for i, idx in enumerate(arr[0]):\n",
        "        if i >= MAX_SEQ_LEN - 1 or idx_is_eos(idx, model):\n",
        "            sentence += model.wv.index2word[idx]\n",
        "            break\n",
        "        else:\n",
        "            sentence += model.wv.index2word[idx] + \" \"\n",
        "    return sentence\n",
        "            \n",
        "def idx_is_eos(idx, model):\n",
        "    return idx == model.wv.vocab['.'].index or idx == model.wv.vocab['!'].index or idx == model.wv.vocab['?'].index\n",
        "\n",
        "seed_sentence = [\"words\", \"go\", \"here\"]\n",
        "sentence_len = 8\n",
        "sent = word_list_to_array(seed_sentence, model_Bad)\n",
        "for i in range(sentence_len):\n",
        "    next_word = bad_model.predict(sent)[0]\n",
        "    new_word = eval(argmax(next_word))\n",
        "#     print(new_word)\n",
        "    sent[0][i + len(seed_sentence)] = new_word\n",
        "    if idx_is_eos(new_word, model_Bad):\n",
        "        break\n",
        "        \n",
        "print(\"Bad Movie Model: [maxlen {}] [seed={}] \".format(sentence_len, seed_sentence) \n",
        "      + array_to_sentence(sent, model_Bad))\n",
        "\n",
        "\n",
        "seed_sentence = [\"words\", \"go\", \"here\"]\n",
        "sentence_len = 8\n",
        "sent = word_list_to_array(seed_sentence, model_Good)\n",
        "for i in range(sentence_len):\n",
        "    next_word = good_model.predict(sent)[0]\n",
        "    new_word = eval(argmax(next_word))\n",
        "    #     print(new_word)\n",
        "    sent[0][i + len(seed_sentence)] = new_word\n",
        "    if idx_is_eos(new_word, model_Good):\n",
        "        break\n",
        "        \n",
        "print(\"Good Movie Model: [maxlen {}] [seed={}] \".format(sentence_len, seed_sentence)\n",
        "      + array_to_sentence(sent, model_Good))"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bad Movie Model: [maxlen 16] [seed=['so', 'if', 'something']] so if something else here goes there now right now there now going back there now now going back .\n",
            "Good Movie Model: [maxlen 16] [seed=['so', 'if', 'something']] so if something wrong is it here now now here now now here today now now now now now .\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}