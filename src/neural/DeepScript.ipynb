{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepScript.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "157DU1t2Z5Yt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Uploading Files onto Google Colab**\n",
        "\n",
        "Word Embeddings have been uploaded on Google Drive in a folder called **Word2Vec**.\n",
        "\n",
        "They were trained by the Gensim module with dimensions of both 200 and 300, window size of 5, and 500 iterations.\n",
        "\n",
        "Here, we will access those files. \n",
        "\n",
        "Note: The URL for Word2Vec is : https://drive.google.com/drive/folders/1ZjAKEl5Nbg6kbM33vNOWIN2FdRfTvYEz?ogsrc=32\n",
        "\n",
        "That is why the q paramter is set to: **1ZjAKEl5Nbg6kbM33vNOWIN2FdRfTvYEz**\n",
        "\n",
        "It is the id that I want the root to search for. "
      ]
    },
    {
      "metadata": {
        "id": "4ufZnIqP_GWV",
        "colab_type": "code",
        "outputId": "2f317499-5f4a-487f-ae72-c3c440e10a42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "local_download_path = os.path.expanduser('~/Word2Vec')\n",
        "try:\n",
        "  os.makedirs(local_download_path)\n",
        "except: pass\n",
        "\n",
        "file_list = drive.ListFile(\n",
        "    {'q': \"'1ZjAKEl5Nbg6kbM33vNOWIN2FdRfTvYEz' in parents\"}).GetList()\n",
        "\n",
        "for f in file_list:\n",
        "  # 3. Create & download by id.\n",
        "  print('title: %s, id: %s' % (f['title'], f['id']))\n",
        "  fname = os.path.join(local_download_path, f['title'])\n",
        "  print('downloading to {}'.format(fname))\n",
        "  f_ = drive.CreateFile({'id': f['id']})\n",
        "  f_.GetContentFile(fname)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: Tokenized Good Sentences.csv, id: 1FBrCGaOPpM4XJ-H4EQJJ030SruW8OSHU\n",
            "downloading to /root/Word2Vec/Tokenized Good Sentences.csv\n",
            "title: Tokenized Bad Sentences.csv, id: 1TKPq7ztGULn61goNyEPQCuDMYL2O_rr7\n",
            "downloading to /root/Word2Vec/Tokenized Bad Sentences.csv\n",
            "title: word2vec_Good_200, id: 1Cuyppnh1ZkhyYLXkwgf8MpvEeYcLp8zk\n",
            "downloading to /root/Word2Vec/word2vec_Good_200\n",
            "title: word2vec_Bad_200, id: 1Hn0CLiSe-f4i7NUrJT3cIFQAmOuUnb3V\n",
            "downloading to /root/Word2Vec/word2vec_Bad_200\n",
            "title: word2vec_Good_300, id: 17W1EyYgsYPcwWG9XZWMQc3f2DSv9bMKy\n",
            "downloading to /root/Word2Vec/word2vec_Good_300\n",
            "title: word2vec_Bad_300, id: 12A6-2bU39EQ12rBVtca4nlRSBUCaO1C3\n",
            "downloading to /root/Word2Vec/word2vec_Bad_300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uJT1SxtinnjM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Importing Tokenized Sentences\n",
        "\n",
        "I have also uploaded two csv files called **Tokenized Bad Sentences.csv** and **Tokenized Good Sentences.csv**  found in the Word2Vec folder. \n",
        "\n",
        "Below is the code to read in those files."
      ]
    },
    {
      "metadata": {
        "id": "xfdxBIsSkjuk",
        "colab_type": "code",
        "outputId": "c8df6883-e2f3-4aab-b143-fc9f88c32a12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "cell_type": "code",
      "source": [
        "import csv\n",
        "with open('/root/Word2Vec/Tokenized Bad Sentences.csv', 'r', encoding=\"latin-1\") as f:\n",
        "    reader = csv.reader(f)\n",
        "    badSentences = list(reader)\n",
        "    \n",
        "with open('/root/Word2Vec/Tokenized Good Sentences.csv', 'r', encoding=\"latin-1\") as f:\n",
        "    reader = csv.reader(f)\n",
        "    goodSentences = list(reader)\n",
        "    \n",
        "print(badSentences[0:10])   \n",
        "print(goodSentences[0:10])  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['oh', ',', 'shit', '.'], ['you', 'just', 'got', 'wolfed', '.'], ['what', '?'], ['that', 'is', 'an', 'official', 'trademark', 'that', 'i', 'am', 'getting', 'registered', '.'], ['it', \"'s\", 'a', 'lot', 'of', 'stuff', 'you', 'got', 'ta', 'do', ',', 'hoops', 'you', 'got', 'ta', 'jump', 'through', '.'], ['got', 'ta', 'get', 'on', 'the', 'internet', '.'], ['got', 'ta', 'go', 'to', 'some', 'stupidass', 'website', 'where', 'you', 'register', 'a', 'catch', 'phrase', '.'], ['i', 'wanted', '``', 'bam', ',', \"''\", 'but', 'emeril', 'had', 'taken', 'it', '.'], ['i', \"'m\", 'rambling', ',', 'man', '.'], ['get', 'up', ',', 'man', '.']]\n",
            "[['mr.', 'dufresne', ',', 'describe', 'the', 'confrontation', 'you', 'had', 'with', 'your', 'wife', 'the', 'night', 'she', 'was', 'murdered', '.'], ['it', 'was', 'very', 'bitter', '.'], ['she', 'said', 'she', 'was', 'glad', 'i', 'knew', ',', 'that', 'she', 'hated', 'all', 'the', 'sneaking', 'around', '.'], ['and', 'she', 'said', 'that', 'she', 'wanted', 'a', 'divorce', 'in', 'reno', '.'], ['what', 'was', 'your', 'response', '?'], ['i', 'told', 'her', 'i', 'would', 'not', 'grant', 'one', '.'], ['``', 'i', \"'ll\", 'see', 'you', 'in', 'hell', 'before', 'i', 'see', 'you', 'in', 'reno', '.'], [\"''\", 'those', 'were', 'your', 'words', ',', 'according', 'to', 'your', 'neighbors', '.'], ['if', 'they', 'say', 'so', '.'], ['i', 'really', 'do', \"n't\", 'remember', '.']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YmIy6TDWaJ0k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Installing gensim**\n",
        "\n",
        "Gensim is the Python module used to train the word2vec embeddings. Here is how to upload the files."
      ]
    },
    {
      "metadata": {
        "id": "cfn6Z8SxXu4W",
        "colab_type": "code",
        "outputId": "d387c1a8-4b45-4477-cc15-e3fddac747c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q gensim\n",
        "from gensim.models import Word2Vec\n",
        "model_Bad = Word2Vec.load(\"/root/Word2Vec/word2vec_Bad_300\")\n",
        "model_Good = Word2Vec.load(\"/root/Word2Vec/word2vec_Good_300\")\n",
        "print(model_Bad)\n",
        "print(model_Good)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=29504, size=300, alpha=0.025)\n",
            "Word2Vec(vocab=30426, size=300, alpha=0.025)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qUR_r-pdaQRD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Similar Vectors**\n",
        "\n",
        "Once the word2vec embeddings are uploaded, you can view the vectors most similar to a given word. "
      ]
    },
    {
      "metadata": {
        "id": "D33t0UbuZaHI",
        "colab_type": "code",
        "outputId": "14305062-1dcd-473c-8133-44e3dd7219e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "cell_type": "code",
      "source": [
        "for i in model_Bad.wv.most_similar (positive = 'good'):\n",
        "  print(i)\n",
        "  \n",
        "print()\n",
        "\n",
        "for i in model_Good.wv.most_similar (positive = 'good'):\n",
        "  print(i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('bad', 0.42860960960388184)\n",
            "('nice', 0.40062108635902405)\n",
            "('like', 0.3491782248020172)\n",
            "('tough', 0.3429213762283325)\n",
            "('great', 0.34254634380340576)\n",
            "('better', 0.28865498304367065)\n",
            "('big', 0.28429123759269714)\n",
            "('weird', 0.2701437175273895)\n",
            "('happy', 0.26822713017463684)\n",
            "('hard', 0.26718002557754517)\n",
            "\n",
            "('bad', 0.5157124996185303)\n",
            "('nice', 0.42234158515930176)\n",
            "('great', 0.3885391056537628)\n",
            "('smart', 0.3636835813522339)\n",
            "('fine', 0.3554360568523407)\n",
            "('tough', 0.34922707080841064)\n",
            "('big', 0.3384079933166504)\n",
            "('funny', 0.33056941628456116)\n",
            "('hard', 0.3305012583732605)\n",
            "('tempting', 0.31914812326431274)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "NQJC4RcYfTQw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Word2Vec Weights onto Keras**\n",
        "\n",
        "Because we are going to use Keras to train an RNN, here is how to extract the actual pretrained weights of the word embedding which can be used for the neural network."
      ]
    },
    {
      "metadata": {
        "id": "ouLu8Z-Ja4x6",
        "colab_type": "code",
        "outputId": "939332f4-1d0b-417e-f04e-10d81fff57a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding\n",
        "\n",
        "pretrained_weights_Bad = model_Bad.wv.vectors \n",
        "#pretrained_weights_Good = model_Good.wv.vectors\n",
        "\n",
        "embeddingBad = Embedding(input_dim=pretrained_weights_Bad.shape[0], output_dim=pretrained_weights_Bad.shape[1], \n",
        "                    weights=[pretrained_weights_Bad])\n",
        "\n",
        "# embeddingGood = Embedding(input_dim=pretrained_weights_Good.shape[0], output_dim=pretrained_weights_Good.shape[1], \n",
        "#                     weights=[pretrained_weights_Good])\n",
        "\n",
        "print(pretrained_weights_Bad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[ 1.25372    -1.2052641  -0.25990063 ... -0.976092    1.8551047\n",
            "   1.3307298 ]\n",
            " [ 1.4823085  -1.2304381  -0.9231364  ... -1.6590116   1.3164423\n",
            "   0.8863562 ]\n",
            " [ 2.0804706  -0.7694774   0.17020172 ... -0.5701194   1.6237695\n",
            "   1.2792978 ]\n",
            " ...\n",
            " [ 0.6441616   0.12467387  0.17375445 ...  0.27845207  0.394679\n",
            "  -0.18595086]\n",
            " [ 0.70862037  0.14693536  0.24079292 ...  0.2610408   0.41543\n",
            "  -0.17618927]\n",
            " [-0.08563908  0.16787037 -0.30501494 ...  0.32231143  0.14400984\n",
            "   0.1407564 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GwiBPHfmqBAA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# LSTM Neural Network\n",
        "\n",
        "Here, we design the architecture for the RNN nerual network. "
      ]
    },
    {
      "metadata": {
        "id": "SKGPGSQTCl5C",
        "colab_type": "code",
        "outputId": "1b2df90a-fff1-4eec-c83e-59e0071f3a7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense\n",
        "from keras.layers import LSTM\n",
        "\n",
        "vocab_size, emdedding_size = pretrained_weights_Bad.shape\n",
        "\n",
        "model = Sequential()\n",
        "model.add(embeddingBad)\n",
        "model.add(LSTM(units=emdedding_size))\n",
        "model.add(Dense(units = vocab_size))\n",
        "model.add(Activation('softmax'))\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 300)         8851200   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 300)               721200    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 29504)             8880704   \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 29504)             0         \n",
            "=================================================================\n",
            "Total params: 18,453,104\n",
            "Trainable params: 18,453,104\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5Se5ALUkdwJd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# train_x = np.zeros([len(badSentences), 1040], dtype=np.int32)\n",
        "# train_y = np.zeros([len(badSentences)], dtype=np.int32)\n",
        "\n",
        "# for i, sentence in enumerate(badSentences):\n",
        "#   for t, word in enumerate(sentence[:-1]):\n",
        "#     train_x[i, t] = model_Bad.wv.vocab[word].index\n",
        "#   train_y[i] = model_Bad.wv.vocab[sentence[-1]].index\n",
        "\n",
        "# print(train_x[0:10])\n",
        "# # compile model\n",
        "# model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# # fit model\n",
        "# model.fit(X, y, batch_size=128, epochs=100)\n",
        " \n",
        "# # save the model to file\n",
        "# model.save('model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}